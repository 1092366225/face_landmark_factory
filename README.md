# facial-landmark-factory (Face landmark detection production system)

## Project Description

[facial-landmark-factory] (https://github.com/songhengyang/face_landmark_factory) is a face landmark detection production system written in Python, using Tensorflow r1.13 and subsequent high-level components Keras and Data. The users can use the built-in detection model of the system to process images and video data containing human faces, and can conveniently implement functions such as automatic annotation of facial landmark, manual position correction of points, data format conversion, and face landmark detection model training. Finally, it is possible to quickly generate a customized face landmark detection model suitable for a specific application scenario.

## Features

1.The system can automatically detect and collect the frames containing the face data in the video data, and automatically mark the face using the built-in face landmark detection model.

2.Using the tools provided by the system, the users can manually correct the positions of the face landmark generated by the automatic labeling tool.

3.The system can convert the format of the annotated data file and convert it to generate the data format recognized by tensorflow.

4.There are seven mainstream deep learning neural networks built in the system. Users can use the built-in neural network to train private data to generate customized face landmark detection models suitable for specific application scenarios.

5.The user can adjust the built-in algorithm, modify the deep learning neural network, and optimize the effect of face landmark detection.

## Quick Start

The test program starts: ./testing/test_webcam.py

Test program exit: Press q

(Note: test_webcam.py reads the local video file vid.avi by default. If you want to use the camera as a video input source, you need to modify the "VIDEO_PATH" parameter.)

Parameter Description:

1.current_model, file of model

Such as: current_model = "../model/facial_landmark_cnn.pb"

2.VIDEO_PATH, video file path

Such as: = "../data/vid.avi" or VIDEO_PATH = 0 (0 means using a local camera as a video source)

3.CNN_INPUT_SIZE, the height of the network input image (the same width and height)

Such as: CNN_INPUT_SIZE = 64,

<p align="center">
<img src="https://github.com/songhengyang/face_landmark_factory/blob/master/data/smpl.gif", width="690">
</p>
<div align="center">
&nbsp;
</div>

## Operating environment
1. ubuntu 16.04.2

## Dependency
1. tensorflow 1.13
2. keras 2.0 and above
3. opencv 3.4 and above
4. python3

## Tutorial
1. <a href="#1">Automatic annotation of video files</a>
2. <a href="#2">Data Preprocessing</a>
3. <a href="#3">Data Training</a>
4. <a href="#4">Model Conversion</a>
5. <a href="#5">Model Testing</a>


### <a name="1">Automatic annotation of video files</a>

- ./data_generate/video_auto_label.py

The tool reads the video file, uses the built-in facial landmark detection model of the system, recognizes the face image appearing in the frames, automatically performs face landmark annotation, generates a pts format file, the face image file and pts formatted dimension files are stored in the same directory.

Parameter Description:

MODEL_FILE, face landmark detection model file path,

Such as: MODEL_FILE = "../model/facial_landmark_MobileNet.pb"

VIDEO_PATH, video file path,

Such as: VIDEO_PATH = "../data/IU.avi"

OUTPUT_DIR, the face image and the path to the pts format annotation file,

Such as: OUTPUT_DIR = "../data/out"

CNN_INPUT_SIZE, neural network input image size, length and width are equal,

CNN_INPUT_SIZE = 64

### <a name="2">Data Preprocessing</a>

- ./data_generate/from_pts_to_json_box_image.py

    The tool reads the annotation data file in pts format, calculates the positions of the generated face box, and then writes the face frame position data and the face annotation data into the face box position file and the face annotation file in json format.

    Parameter Description:

    INPUT_LIST, which stores a directory listing of pts annotation files,
    
    Such as: INPUT_LIST = ["../data/out"]

    OUTPUT_DIR, converted to the path of the face box position data file and the face label data file in json format,

    
    Such as: OUTPUT_DIR = "../data/json"

- ./data_generate/manual_correct_label.py

    This tool helps the user to manually correct the postions of the face landmark. The tool reads the original image file, the face box positions file of the jason format, and the face landmark annotation file, and displays the image of the face box and the landmark that has been marked, and the user can use the keyboard to correct the positions of the landmark. The facial landmark are manually corrected, and finally the corrected face box position file and the face landmark file are generated.
    
    Parameter Description:

    INPUT_DIR, the face box positions file directory and the upper level directory of the face landmark file directory

    
    Such as: INPUT_DIR = "../data/json"

    Instructions for correcting the facial labelling positions using the keyboard (requires activation by click the right button):

    Press the space bar: next image file

    Press b: the previous image file

    Press q: the last point

    Press e: the next point

    Press a: shifts one pixel to the left

    Press d: shifts one pixel to the right

    Press the w key: moves to next pixel

    Press s: the feature point moves to last pixel

    Program exit:

    Press the Esc key

- ./data_generate/gen_argment.py

    The tool uses a limited number of face image datasets to generate augment datasets based on rules to improve model training. The tool reads the facial image file and the facial landmark detection annotation file of the specified directory, and generates an augment data set according to the built-in rules of the tool. Training with augment data sets can greatly improve the training effect of deep learning neural networks and generate an optimized face landmark detection model.

    INDIR_LIST, the facial image file directory and the face landmark detection list of the upper directory of the annotation file directory.

    
    Such as: INDIR_LIST = ["../data/json","../data/json01"]
    
    
    OUTPUT_DIR, enhanced dataset file directory
    
    
    Such as: OUTPUT_DIR = "../data/augment"
    

- ./data_generate/gen_tfrecord.py


    The tool reads the data set of the specified directory and generates a tfrecords format data file for tensorflow training.
    

    Input_list, a directory list that stores data sets
    
    
    Such as: input_list = ["../data/json","../data/json01"]
    

    Tfrecord_file_dir, the storage directory of the tfrecords format data file generated by the tool.
    
    
    Such as: tfrecord_file_dir = "../data/tfrecord"
    

    Index_extract is used to generate a list of face landmark numbers in the tfrecords format data file. The empty list is to extract all points.
  
    
    Such as: index_extract = []
    

### <a name="3">Data Training</a>


- ./training/train_models.py


    The tool reads the tfrecord format training data set in the specified directory, and uses the user-selected neural network (a total of 7 types) to train and generate the facial landmarkdetection model. The model format is h5 (keras can read).
    

    DATA_DIR, training data path in tfrecord format
    
    
    Such as: DATA_DIR = "../data/tfrecord"
    

    LOADING_PRETRAIN, pre-training switch (True/False)
    
    
    Such as: LOADING_PRETRAIN = False
    
    
    BATCH_SIZE, BATCH

    
    Such as: BATCH_SIZE = 10
    
    
    STEPS_PER_EPOCH, the amount of training data
    
    
    Such as: STEPS_PER_EPOCH = 100
    
    
    TEST_STEPS, the number of test data
    
    
    Such as: TEST_STEPS = 11
    
    
    EPOCHS, training iterations
    
    
    Such as: EPOCHS = 1000
    
    IMAGE_SIZE, image pixel value (length and width values are the same)
    
    
    Such as: IMAGE_SIZE = 64
    
    
    (Note: Tool training newly generated facial landmark detection model file path: ../model/facial_landmark_SqueezeNet.h5) 

###<a name="4">Model Conversion</a>


- ./model_converter/h5_to_pb.py,

    The tool converts h5 model files into pb model files, showing input and output layer names.
    

- ./model_converter/to_tflite.sh,

    This tool converts pb model files into tflite model files.
    

### <a name="5">Model Testing</a>


- ./testing/test_webcam.py


    Generated pb format model can be used to test the facial landmark detection model training effect.
    

    The test program starts:
    
    
    ./testing/test_webcam.py
    

    Test program exit:
    
    
    Press q
    

## Quotation


1. https://github.com/yinguobing/cnn-facial-landmark


## Copyright
